,topic,subreddit,title,score,id,url,created,body
0,CVE,devops,I have created a small project to track daily ECR vulnerability scans,1,ekh4bu,https://www.reddit.com/r/devops/comments/ekh4bu/i_have_created_a_small_project_to_track_daily_ecr/,2020-01-06 05:47:21,"**Initial problem:** In the end of October 2019 AWS has finally introduced a way to vulnerability scan ECR images natively (via Console). While I have waited a long time for this feature, I was a bit disappointed with the reporting tools that came with it. AWS proposes this architecture in order to receive daily scan reports: [URL Honestly I find it a bit of an overkill, especially that I like to tunnel reports / notifications into Slack. **My solution:** During Christmas break I have created two small Lambda functions (golang): \- One to trigger daily re-scan \- One to send a digested report to an arbitrary Slack channel with a link pointing to the original report in Console The Lambdas runs as CloudWatch Events and deployed by serverless. (via CloudFormation) I am fairly satisfied with the outcome, the project has been running in production for more than a week. Of course there can be bugs, you are welcome to report them or contribute via Github. The repository: [URL I welcome you to use it and provide any feedback, or share any other solutions you are using. If you need help setting it up or have any questions, feel free to DM. **Future:** The project was finished in a bit of a rush, so it concentrates on sending reports to Slack only. I understand that Slack is not the ideal tool for everyone to receive reports into so I am planning to refactor and extend the code to support: \- sending report via email \- sending report to SNS topic \- you name it I hope that this post doesn't go against community rules, in spite of being a ""personal"" project. I think it solves a specific problem and may help others as well. If moderators find it as a violation, I will gladly remove it. Also, I am not sure whether the ""no personal info"" rule applies to the post's text exclusively, or means that I cannot include links that may expose personal information."
1,CVE,devops,Show devops: dep-scan is a free open-source dependency audit tool built for CI,1,exp7n3,https://www.reddit.com/r/devops/comments/exp7n3/show_devops_depscan_is_a_free_opensource/,2020-02-03 01:32:30,"Thanks reddit for the fantastic support (and sponsorship!) you gave me when I announced my previous project - a free open-source SAST tool called [sast-scan](URL Working on sast-scan gave me several useful insights into the world of vulnerabilities, CVE, CWE and so on. So it made natural sense to implement a new [dependency scanner](URL for modern DevOps and DevSecOps folks. If you are used to using dependency-check and those commercial scanners you will find dep-scan to be a lot more performant. Give this project a try and let me know your thoughts."
2,CVE,devops,"management of installed software, it's versions, and available (security) updates",1,e1i1m0,https://www.reddit.com/r/devops/comments/e1i1m0/management_of_installed_software_its_versions_and/,2019-11-26 03:03:28,"I am looking for a general term / solution to get an overview of an IT landscape not limited to servers, but everything that might be installed somewhere. it's available versions, updates, (classification if security yes/no), end of support / life for that software and probably lots more info on that software. Usually you'd be able to get this by looking at the local package manager, but if managing clients with all sorts of OS there's not one package manager but multiple. same goes for the extend to software packages within a development cycle (some node.js library that has been installed, some php dependency etc.) I wonder if there's a tool to that I can browse for a term like ""apache 2.2"" -&gt; see it's marked for old version / reached EOL. or query for ""apache 2.4"" see everyting still fine. some software packages might come with a LTS version, so a targeted EOL being sometime in x years (usually OS systems have that). What would be a good starting point, other than a custom spreadsheet, wikipedia, release notes of said software on their respecting websites and access to CVE database plus lots of manual work to put the info together?"
3,CVE,devops,Software Inventarisation for Containers?,1,e5yn1f,https://www.reddit.com/r/devops/comments/e5yn1f/software_inventarisation_for_containers/,2019-12-04 23:39:41,"Hi, i know, for CVE/Security Scanning there are tools like clair and snyk... but.. are there tools which do software-inventarisation? like list all the packages of the software? does anyone know something like that?"
4,CVE,devops,Critical Kubernetes security flaw (CVE-2018-1002105) explained in plain English,1,a2yui2,https://www.reddit.com/r/devops/comments/a2yui2/critical_kubernetes_security_flaw_cve20181002105/,2018-12-04 19:30:30,"The Kubernetes project just had one of its most critical security issues. The flaw has been found and patched for the supported versions of Kubernetes, but we as DevOps engineers need to roll out the update. You are very likely affected unless you have updated in the last two days or so (or run 1.13 already). This blog post explains the bug in plain English and links to the relevant Github Issue and mailing list announcement. URL"
5,CVE,devops,Rethinking 3rd party artifacts eco-system,1,9pvqeg,https://www.reddit.com/r/devops/comments/9pvqeg/rethinking_3rd_party_artifacts_ecosystem/,2018-10-21 03:59:38,"Current 3rd party repositories like those for Maven, npm, Nuget etc. are hopelessly vulnerable for undirected, mass attacks with infected libraries. Some artefacts have MD5 and SHA1 integrity checksums, some even pgp signatures, but even then those signatures are mostly self-signed. Other repositories do not even have those pgp signatures, because open source devs find this too cumersome (so I am told). I think we need a re-design/rethink the 3rd party eco-system to prevent socalled Supply Chain Attacks or Cross Build Injection (XBI). My suggestions : \- HTTPS transport only. I cannot understand why [URL s and [URL still run ! \- make pgp artefact signing as simple as what Let'sencrypt did for websites, for ALL repository-types. \- make pgp signing and SHA256 checksums mandatory across all repositories \- create a flexible common infrastructure that serves any kind of artefacts, that can be verified on integrity and authenticity. This project looks promising : [URL or [URL \- separate repositories for different levels of maturity (production/development/testing/staging) and for instance for quarantined artefacts, artefacts taken out of service, black-listed dependencies. each repository can have its own security policy : 1. PGP signature (root signed or not etc.) and SHA checksum validation 2. content validation (does the file extension match the real file content) 3. CVE threat level, and transitive threat level 4. licence compliance 5. API compliance of updates against previous versions 6. max size the open source community should not have to rely on commercial products for these features. Let's build this ourselves. Who has comments or suggestions ? Are there already steps in this directions ? Kind regards, javabean\_."
6,CVE,devops,CVE scanner,2,7l18kj,https://www.reddit.com/r/devops/comments/7l18kj/cve_scanner/,2017-12-21 00:00:25,"I'm looking for tools that can scan the system for CVE. So far I've found URL (does anybody use it? opinions?), but I'm curious if you have any other tools that you use in your environments. I'm mostly interested in scanning Debian."
7,CVE,devops,CVE-2016-9962: Run Container Run,27,5oo850,https://www.reddit.com/r/devops/comments/5oo850/cve20169962_run_container_run/,2017-01-18 19:25:12,"Recently, an interesting vulnerability was discovered (CVE-2016-9962) that enables container escape to the host. The vulnerability stems from a bug found in opencontainers' runc code, which is used by several container engines, including Docker. The vulnerability is exploited when exec-ing a command inside an already running container. When that happens, a malicious process inside the container can access a forgotten file descriptor of a directory that resides on the host. This in turn can be used to perform directory traversal to the host's file system, thus facilitating a nasty and easy escape. Check out what happened, and how to fix it: URL "
8,CVE,devops,"Image signatures are necessary, but not adequate. Here's why you can't rely on them alone",7,4v8llo,https://www.reddit.com/r/devops/comments/4v8llo/image_signatures_are_necessary_but_not_adequate/,2016-07-30 06:15:22,"From: [Signed, Sealed, Deployed: Why Signatures Aren't Enough](URL Red Hat recently blogged about their progress in adding support for container image signing, a particularly interesting and most welcome aspect of the design is the way that the binary signature file can be decoupled from the registry and distributed separately. The blog makes interesting reading and Id strongly recommending reading through it, Im sure youll appreciate the design. And of course code is available on line. Red Hat is, along with the other Linux distributors, well versed in the practice of signing software components to allow end users to verify that they are running authentic code and is in the process of extending this support to container images. The approach described is different to that taken previously by Docker Inc. however rather than comparing the two approaches I wanted to talk at a high level about the benefits of image signing along with some commentary about trust. In the physical world we are all used to using our signature to confirm our identity. Probably the most common example is when we are signing a paper check or using an electronic signature pad during a sales transaction. How many times have you signed your signature so quickly that you do not even recognize it yourself? How many times in recent memory has a cashier or server compared the signature written with that on the back of your credit card? In my experience that check is likely to happen one out of every ten times and even in those cases that check is little more than a token gesture and the two signatures may not have matched. That leads me to the first important observation: a signature mechanism is only useful if it is checked. Obviously when vendors such as Docker Inc, Red Hat and others implement an image signing and validation system, the enforcement will be built into to all layers, so that in one example a Red Hat delivered image will be validated by a Red Hat provided Docker runtime to ensure its signed by a valid source. However its more likely that the images that you deploy in your enterprise wont just be the images downloaded from a registry, but instead images built on top of these images or perhaps even built from scratch, so for image signing to provide the required level of security all images created within your enterprise should also be signed and have those signatures validated before the image is deployed. Some early users of image signing that we have talked to have used image signing less as a way of tracking provenance of images but instead as a method to show that an image has not been modified between leaving the CI/CD pipeline and being deployed on their container host. Before we dig into the topic of image signing its worth discussing what a signature actually represents. The most common example of signatures that we see in our day to day life is in our web browsers where we look for the little green padlock in address bar that indicates that the connection to the web server from our browser is encrypted but most importantly it confirms that you are talking to the expected website. The use of TLS/SSL certificates allows your browser to validate that when you connect to URL the content displayed actually came from example.com. So in this example the signature was used to confirm the source of the (web) content. Over many years we have been trained NOT to type our credit card details into a site that is NOT delivered through HTTPS. But that does not mean that you would trust your credit card details to any site that uses HTTPS. The same principle applies to the use of image signatures. If you download an image signed by Red Hat, Docker Inc, or any other vendor, you can be assured that the image did come from this vendor. The level of confidence you have in the contents of the image is based on the level of trust you already have with the vendor. For example you are likely not to run an image signed by l33thackerz even though it may include a valid signature. As enterprises move to a DevOps model with containers were seeing a new software supply chain, which often begins with a base image pulled from DockerHub or a vendor registry. This base image may be modified by the operations team to include extra packages or to customize specific configuration files. The resulting image is then published in the local registry to be used by the development team as the base image for their application container. In many organizations we are starting to see other participants in this supply chain, for example a middleware team may publish an image containing an application server that is in turn used by an application team. For the promise of image signing to be fulfilled, at each stage of this supply chain each team must sign the image to ensure that the chain of custody can be validated throughout the software development lifecycle. As we covered previously those signatures only serves to prove the source of an image, during any point in the supply chain from the original vendor of the base image all the way through the development process the images may be modified. At any step in the supply chain a mistake may be made, an outdated package that contains known bugs of vulnerabilities may be used, an insecure configuration option in an applications configuration file, or perhaps secrets such as passwords or API keys may be stored in the image. Signing an image will not prevent insecure or otherwise non-compliant images from being deployed, however as part of a post mortem it will provide a way of tracking down when the vulnerability or bug was introduced. During each stage of the supply chain detailed checks should be performed on the image to ensure that the image complies with your site specific policies. These policies could cover security, starting with the ubiquitous CVE scan but then going further to analyze configuration of key security components. For example, you could have the latest version of the Apache web server but have configured the wrong set of TLS Ciphers suites leading to insecure communication. In addition to security, your policies could cover application specific configurations to comply with best practices or to enable consistency and predictability. Anchores goal is to provide a toolset that allows developers, operations, and security teams to maintain full visibility of the chain of custody as containers move through the development lifecycle, while providing the visibility, predictability, and control needed for production deployment. With Anchores tools the analysis and policy evaluation could be run during each stage of the supply chain allowing the signatures to attest to both the source of the image and also the compliance of the images contents. In summary, we believe that image signing is an important part of the security and integrity of your software supply chain however signatures alone will not ensure the integrity of your systems. "
